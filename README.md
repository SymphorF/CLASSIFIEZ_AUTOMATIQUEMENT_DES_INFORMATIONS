# Projet : Classifiez automatiquement des informations

Utilisez des modÃ¨les de classification pour prÃ©dire les dÃ©missions des employÃ©s de l'ESN TechNova Partners.

*Ce projet utilise Python avec Poetry pour la gestion d'environnement virtuel, et JupyterLab pour l'exploration des donnÃ©es.*

# Structure du projet

``` 
Projet /
â”œâ”€â”€ .github/workflows                          # Workflow dÃ©ploiement sur github
â”‚   â””â”€â”€ python-ci-cd.yml                       # Fichier de dÃ©ploiement pour le workflow CI/CD
â”œâ”€â”€ Docs/                                      # Les documents annexes (prÃ©sentation, rapportsâ€¦)
â”‚   â”œâ”€â”€ Scheam_BDD.pdf                         # SchÃ©ma de base de donnÃ©es
â”‚   â”œâ”€â”€ Scheam_BDD.png                         # SchÃ©ma de base de donnÃ©es
â”‚   â””â”€â”€ Fonkou_Symphor_prÃ©sentation.pptx       # PrÃ©sentation PowerPoint du projet
â”œâ”€â”€ FastAPI/                                   # Dossier FastAPI
â”‚   â”œâ”€â”€ __pycache__                            # Dossier pycache stockage des donnÃ©es compilÃ©es
â”‚   â”œâ”€â”€ __init__.py                            # Fichier init pour dÃ©finir le package FastAPI
â”‚   â”œâ”€â”€ main.py                                # Fichier main
â”‚   â”œâ”€â”€ model.py                               # Fichier des classes des donnÃ©es
â”‚   â””â”€â”€ predict.py                             # Fonction de prÃ©diction
â”œâ”€â”€ Notebooks/                                 # Les notebooks Jupyter
â”‚   â”œâ”€â”€ Fonkou_Symphor_1_notebook.ipynb        # PremiÃ¨re partie Notebooks
â”‚   â””â”€â”€ Fonkou_Symphor_2_notebook.ipynb        # DeuxiÃ¨me partie Notebooks
â”œâ”€â”€ PostGreSQL/                                # Fichier PostGreSQL
â”‚   â”œâ”€â”€ Docs                                   # Documents PostGreSQL
â”‚   â”œâ”€â”€ connexion_db_postgresql.ipynb          # Fichier de connexion postgresql Ã  python
â”‚   â””â”€â”€ fichier_rh_db.sql                      # Fichier script SQL 
â”œâ”€â”€ Data/                                      # Les jeux de donnÃ©es (csv)
â”‚   â”œâ”€â”€ extrait_sondage.csv                    # DonnÃ©es brutes
â”‚   â”œâ”€â”€ extrait_sirh.csv                       # DonnÃ©es brutes
â”‚   â”œâ”€â”€ extrait_eval.csv                       # DonnÃ©es brutes
â”‚   â”œâ”€â”€ data.csv                               # DonnÃ©es brutes regroupÃ©es
â”‚   â”œâ”€â”€ data_encoded.csv                       # DonnÃ©es nettoyÃ©s (sans la cible)
â”‚   â””â”€â”€ data_cible_encoded.csv                 # DonnÃ©es nettoyÃ©s (cible uniquement)
â”œâ”€â”€ deploy_hugging_face/                       # Deploiement hugging face
â”‚   â”œâ”€â”€ .gitattributes                         # Fichier de configuration git
â”‚   â”œâ”€â”€ README.md                              # README de hugging face
â”‚   â”œâ”€â”€ app.py                                 # Fichier app pour simulation hugging face
â”‚   â”œâ”€â”€ data_TEST.csv                          # DonnÃ©es de test pour hugging face et FastAPI
â”‚   â”œâ”€â”€ logreg_model.joblib                    # ModÃ¨le de regression logistique en joblib
â”‚   â”œâ”€â”€ rfc_model.joblib                       # ModÃ¨le random forest classifier en joblib
â”‚   â””â”€â”€ requirements.txt                       # Fichier requis pour deploiement hugging face
â”œâ”€â”€ tests/                                     # Fichiers de tests unitaires et fonctionnels
â”‚   â”œâ”€â”€ __pycache__                            # Dossiers pycache stockage des tests compilÃ©s
â”‚   â”œâ”€â”€ test_sample.py                         # Fichier de test (Ã©chantillon)
â”‚   â”œâ”€â”€ test_chargement.py                     # Fichier de test de chargement des donnÃ©es
â”‚   â”œâ”€â”€ test_model.py                          # Fichier de test de modÃ©lisation
â”‚   â”œâ”€â”€ test_preprocessing.py                  # Fichier de test de nettoyage
â”‚   â””â”€â”€ test_fonctionnel_predict_endpoint.py   # Test fonctionnel (affichage des prÃ©dictions selon donnÃ©es d'entrÃ©e)
â”œâ”€â”€ rfc_model.joblib                           # ModÃ¨le rfc joblib pour dÃ©ploiment cd du test fonctionnel
â”œâ”€â”€ poetry.lock                                # Fichier des dÃ©pendances (poetry)
â”œâ”€â”€ pyproject.toml                             # Verrouillage des versions
â”œâ”€â”€ Requirements.txt                           # Ensemble des outils nÃ©cessaires pour ce projet
â””â”€â”€ README.md                                  # README global du projet (Explications du projet)

``` 

ğŸš€ **PrÃ©sentation du projet**
Ce projet vise Ã  prÃ©dire des tendances ou des indicateurs RH Ã  partir de jeux de donnÃ©es combinÃ©s (SIRH, sondage, Ã©valuation). Ã€ lâ€™aide de modÃ¨les comme Logistic Regression ou Random Forest, nous fournissons des prÃ©dictions accessibles via une API FastAPI et dÃ©ployÃ©es aussi via Hugging Face Spaces.

âš™ï¸ **Instructions dâ€™installation**

1. Cloner le dÃ©pÃ´t :

bash

git clone https://github.com/SymphorF/CLASSIFIEZ_AUTOMATIQUEMENT_DES_INFORMATIONS.git

cd CLASSIFIEZ_AUTOMATIQUEMENT_DES_INFORMATIONS


2. CrÃ©er un environnement virtuel :

bash

python -m venv venv

source venv\Scripts\activate 


3. Installer les dÃ©pendances :

bash

pip install -r deploy_hugging_face/requirements.txt
installez poetry :

bash

poetry install



ğŸ§ª **Lancer les tests**

bash

pytest --cov=FastAPI tests/


â–¶ï¸ **Utilisation locale (FastAPI)**

1. DÃ©marrer le serveur FastAPI :

bash

cd FastAPI

uvicorn main:app --reload

ou 

fastapi dev main.py


2. AccÃ©der Ã  la documentation interactive :

Swagger : http://127.0.0.1:8000/docs

Redoc : http://127.0.0.1:8000/redoc



ğŸŒ **DÃ©ploiement**

ğŸ” **GitHub Actions CI/CD**

Un fichier .github/workflows/python-ci-cd.yml gÃ¨re les workflows CI/CD :

* ExÃ©cution des tests Ã  chaque push
* VÃ©rification du code Python (lint, pytest)

ğŸ¤— **Hugging Face**
1. Copier le contenu du dossier deploy_hugging_face/ vers un repo Hugging Face Space.

2. Utiliser app.py comme fichier principal.

3. Les modÃ¨les .joblib doivent Ãªtre prÃ©sents dans le repo.

4. Hugging Face utilise requirements.txt pour les dÃ©pendances.


ğŸ”’ **Bonnes pratiques de sÃ©curitÃ©**

âœ… **Variables secrÃ¨tes**

* Ne jamais stocker de mot de passe, clÃ© API ou URL de base de donnÃ©es en clair dans le code.
* Utiliser un fichier .env pour les secrets 

env

DATABASE_URL=postgresql://user:pwd@localhost/db
SECRET_KEY=your-secret-key


ğŸ“š **Auteurs et crÃ©dits**
Fonkou Symphor

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™un exercice de modÃ©lisation et de dÃ©ploiement dâ€™un systÃ¨me prÃ©dictif RH.